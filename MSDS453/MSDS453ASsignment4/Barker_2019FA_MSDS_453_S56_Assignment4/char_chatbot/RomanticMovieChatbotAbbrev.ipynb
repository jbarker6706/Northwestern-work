{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\" Build character sequence-to-sequence training set \"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"movies-sequence-input.txt\", \"r\") as file_input:\n",
    "    movie_input = file_input.read()\n",
    "df_input = pd.DataFrame(movie_input.split('\\n'),columns=list('i'))\n",
    "df_input = df_input.fillna(' ')\n",
    "\n",
    "with open(\"movies-sequence-output.txt\", \"r\") as file_output:\n",
    "    movie_output = file_output.read()\n",
    "df_output = pd.DataFrame(movie_output.split('\\n'),columns=list('o'))\n",
    "df_output = df_output.fillna(' ')\n",
    "\n",
    "input_texts, target_texts = [], []\n",
    "input_vocabulary = set()\n",
    "output_vocabulary = set()\n",
    "start_token = '\\t'\n",
    "stop_token = '\\n'\n",
    "#max_training_samples = min(25000, len(df_input) - 1)\n",
    "max_training_samples = min(10000, len(df_input) - 1)\n",
    "\n",
    "\n",
    "for input_text, target_text in zip(df_input.i, df_output.o):\n",
    "    target_text = start_token + target_text \\\n",
    "        + stop_token  # <5>\n",
    "    if(len(input_text)>400):\n",
    "        input_texts.append(input_text[:400])\n",
    "    else:\n",
    "        input_texts.append(input_text)\n",
    "    if(len(target_text)>400):\n",
    "        target_texts.append(target_text[:400])\n",
    "    else:\n",
    "        target_texts.append(target_text)\n",
    "    for char in input_text:  # <6>\n",
    "        if char not in input_vocabulary:\n",
    "            input_vocabulary.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in output_vocabulary:\n",
    "            output_vocabulary.add(char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949\n"
     ]
    }
   ],
   "source": [
    "print(df_input.i.str.len().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocabulary = sorted(input_vocabulary)\n",
    "output_vocabulary = sorted(output_vocabulary)\n",
    "\n",
    "input_vocab_size = len(input_vocabulary)\n",
    "output_vocab_size = len(output_vocabulary)\n",
    "\n",
    "max_encoder_seq_len = df_input.i.str.len().max()\n",
    "max_decoder_seq_len = df_output.o.str.len().max()\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_vocabulary)])\n",
    "\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(output_vocabulary)])\n",
    "\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_encoder_seq_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cc340cda81ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m encoder_input_data = np.zeros(\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_encoder_seq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_vocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     dtype='float32')\n\u001b[0;32m      6\u001b[0m decoder_input_data = np.zeros(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_encoder_seq_length' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, input_vocab_size),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, output_vocab_size),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, output_vocab_size),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(\n",
    "        zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[\n",
    "            i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[\n",
    "            i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9562\n",
      "400\n",
      "92\n",
      "351881600\n"
     ]
    }
   ],
   "source": [
    "print(len(input_texts))\n",
    "print(max_encoder_seq_length)\n",
    "print(input_vocab_size)\n",
    "print(len(input_texts) * max_encoder_seq_length*input_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jbark\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\jbark\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\jbark\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 8605 samples, validate on 957 samples\n",
      "Epoch 1/100\n",
      "8605/8605 [==============================] - 154s 18ms/step - loss: 0.3874 - acc: 0.0289 - val_loss: 0.3664 - val_acc: 0.0356\n",
      "Epoch 2/100\n",
      "8605/8605 [==============================] - 158s 18ms/step - loss: 0.3265 - acc: 0.0366 - val_loss: 0.3224 - val_acc: 0.0439\n",
      "Epoch 3/100\n",
      "8605/8605 [==============================] - 161s 19ms/step - loss: 0.2924 - acc: 0.0437 - val_loss: 0.2931 - val_acc: 0.0482\n",
      "Epoch 4/100\n",
      "8605/8605 [==============================] - 291s 34ms/step - loss: 0.2734 - acc: 0.0474 - val_loss: 0.2759 - val_acc: 0.0531\n",
      "Epoch 5/100\n",
      "8605/8605 [==============================] - 394s 46ms/step - loss: 0.2604 - acc: 0.0505 - val_loss: 0.2669 - val_acc: 0.0546\n",
      "Epoch 6/100\n",
      "8605/8605 [==============================] - 163s 19ms/step - loss: 0.2502 - acc: 0.0532 - val_loss: 0.2569 - val_acc: 0.0567\n",
      "Epoch 7/100\n",
      "8605/8605 [==============================] - 149s 17ms/step - loss: 0.2413 - acc: 0.0555 - val_loss: 0.2482 - val_acc: 0.0595\n",
      "Epoch 8/100\n",
      "8605/8605 [==============================] - 152s 18ms/step - loss: 0.2337 - acc: 0.0574 - val_loss: 0.2427 - val_acc: 0.0612\n",
      "Epoch 9/100\n",
      "8605/8605 [==============================] - 149s 17ms/step - loss: 0.2274 - acc: 0.0588 - val_loss: 0.2353 - val_acc: 0.0629\n",
      "Epoch 10/100\n",
      "8605/8605 [==============================] - 152s 18ms/step - loss: 0.2214 - acc: 0.0602 - val_loss: 0.2317 - val_acc: 0.0639\n",
      "Epoch 11/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.2164 - acc: 0.0615 - val_loss: 0.2261 - val_acc: 0.0658\n",
      "Epoch 12/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.2120 - acc: 0.0626 - val_loss: 0.2225 - val_acc: 0.0657\n",
      "Epoch 13/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.2080 - acc: 0.0635 - val_loss: 0.2216 - val_acc: 0.0665\n",
      "Epoch 14/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.2042 - acc: 0.0646 - val_loss: 0.2201 - val_acc: 0.0672\n",
      "Epoch 15/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.2009 - acc: 0.0654 - val_loss: 0.2136 - val_acc: 0.0685\n",
      "Epoch 16/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1978 - acc: 0.0662 - val_loss: 0.2120 - val_acc: 0.0688\n",
      "Epoch 17/100\n",
      "8605/8605 [==============================] - 148s 17ms/step - loss: 0.1950 - acc: 0.0669 - val_loss: 0.2084 - val_acc: 0.0701\n",
      "Epoch 18/100\n",
      "8605/8605 [==============================] - 148s 17ms/step - loss: 0.1932 - acc: 0.0674 - val_loss: 0.2074 - val_acc: 0.0702\n",
      "Epoch 19/100\n",
      "8605/8605 [==============================] - 149s 17ms/step - loss: 0.1900 - acc: 0.0683 - val_loss: 0.2061 - val_acc: 0.0709\n",
      "Epoch 20/100\n",
      "8605/8605 [==============================] - 150s 17ms/step - loss: 0.1876 - acc: 0.0689 - val_loss: 0.2038 - val_acc: 0.0714\n",
      "Epoch 21/100\n",
      "8605/8605 [==============================] - 148s 17ms/step - loss: 0.1854 - acc: 0.0695 - val_loss: 0.2027 - val_acc: 0.0716\n",
      "Epoch 22/100\n",
      "8605/8605 [==============================] - 153s 18ms/step - loss: 0.1834 - acc: 0.0700 - val_loss: 0.2023 - val_acc: 0.0717\n",
      "Epoch 23/100\n",
      "8605/8605 [==============================] - 148s 17ms/step - loss: 0.1815 - acc: 0.0705 - val_loss: 0.2025 - val_acc: 0.0712\n",
      "Epoch 24/100\n",
      "8605/8605 [==============================] - 148s 17ms/step - loss: 0.1798 - acc: 0.0710 - val_loss: 0.2000 - val_acc: 0.0725\n",
      "Epoch 25/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1778 - acc: 0.0715 - val_loss: 0.1994 - val_acc: 0.0725\n",
      "Epoch 26/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1761 - acc: 0.0720 - val_loss: 0.1994 - val_acc: 0.0725\n",
      "Epoch 27/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1745 - acc: 0.0724 - val_loss: 0.1987 - val_acc: 0.0726\n",
      "Epoch 28/100\n",
      "8605/8605 [==============================] - 152s 18ms/step - loss: 0.1729 - acc: 0.0729 - val_loss: 0.1979 - val_acc: 0.0730\n",
      "Epoch 29/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1713 - acc: 0.0733 - val_loss: 0.1977 - val_acc: 0.0731\n",
      "Epoch 30/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1699 - acc: 0.0736 - val_loss: 0.1974 - val_acc: 0.0732\n",
      "Epoch 31/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1685 - acc: 0.0741 - val_loss: 0.1967 - val_acc: 0.0733\n",
      "Epoch 32/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1671 - acc: 0.0745 - val_loss: 0.1964 - val_acc: 0.0735\n",
      "Epoch 33/100\n",
      "8605/8605 [==============================] - 148s 17ms/step - loss: 0.1658 - acc: 0.0749 - val_loss: 0.1969 - val_acc: 0.0733\n",
      "Epoch 34/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1646 - acc: 0.0752 - val_loss: 0.1967 - val_acc: 0.0735\n",
      "Epoch 35/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1632 - acc: 0.0756 - val_loss: 0.1978 - val_acc: 0.0732\n",
      "Epoch 36/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1619 - acc: 0.0760 - val_loss: 0.1975 - val_acc: 0.0732\n",
      "Epoch 37/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1607 - acc: 0.0763 - val_loss: 0.1975 - val_acc: 0.0733\n",
      "Epoch 38/100\n",
      "8605/8605 [==============================] - 149s 17ms/step - loss: 0.1594 - acc: 0.0767 - val_loss: 0.1986 - val_acc: 0.0731\n",
      "Epoch 39/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1582 - acc: 0.0770 - val_loss: 0.1988 - val_acc: 0.0731\n",
      "Epoch 40/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1571 - acc: 0.0774 - val_loss: 0.1975 - val_acc: 0.0735\n",
      "Epoch 41/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1559 - acc: 0.0777 - val_loss: 0.1991 - val_acc: 0.0729\n",
      "Epoch 42/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1548 - acc: 0.0781 - val_loss: 0.1991 - val_acc: 0.0732\n",
      "Epoch 43/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1537 - acc: 0.0783 - val_loss: 0.1989 - val_acc: 0.0734\n",
      "Epoch 44/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1526 - acc: 0.0787 - val_loss: 0.1998 - val_acc: 0.0731\n",
      "Epoch 45/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1516 - acc: 0.0790 - val_loss: 0.2000 - val_acc: 0.0729\n",
      "Epoch 46/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1504 - acc: 0.0793 - val_loss: 0.2025 - val_acc: 0.0723\n",
      "Epoch 47/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1494 - acc: 0.0796 - val_loss: 0.2020 - val_acc: 0.0731\n",
      "Epoch 48/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1483 - acc: 0.0800 - val_loss: 0.2030 - val_acc: 0.0728\n",
      "Epoch 49/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1473 - acc: 0.0803 - val_loss: 0.2038 - val_acc: 0.0725\n",
      "Epoch 50/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1463 - acc: 0.0805 - val_loss: 0.2043 - val_acc: 0.0723\n",
      "Epoch 51/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1453 - acc: 0.0809 - val_loss: 0.2041 - val_acc: 0.0724\n",
      "Epoch 52/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1444 - acc: 0.0811 - val_loss: 0.2051 - val_acc: 0.0724\n",
      "Epoch 53/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1434 - acc: 0.0814 - val_loss: 0.2054 - val_acc: 0.0721\n",
      "Epoch 54/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1423 - acc: 0.0818 - val_loss: 0.2059 - val_acc: 0.0720\n",
      "Epoch 55/100\n",
      "8605/8605 [==============================] - 148s 17ms/step - loss: 0.1414 - acc: 0.0820 - val_loss: 0.2078 - val_acc: 0.0718\n",
      "Epoch 56/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1405 - acc: 0.0823 - val_loss: 0.2085 - val_acc: 0.0720\n",
      "Epoch 57/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1395 - acc: 0.0826 - val_loss: 0.2096 - val_acc: 0.0713\n",
      "Epoch 58/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1386 - acc: 0.0828 - val_loss: 0.2097 - val_acc: 0.0715\n",
      "Epoch 59/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1377 - acc: 0.0832 - val_loss: 0.2101 - val_acc: 0.0717\n",
      "Epoch 60/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1368 - acc: 0.0835 - val_loss: 0.2111 - val_acc: 0.0716\n",
      "Epoch 61/100\n",
      "8605/8605 [==============================] - 150s 17ms/step - loss: 0.1359 - acc: 0.0837 - val_loss: 0.2121 - val_acc: 0.0713\n",
      "Epoch 62/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1350 - acc: 0.0840 - val_loss: 0.2145 - val_acc: 0.0710\n",
      "Epoch 63/100\n",
      "8605/8605 [==============================] - 146s 17ms/step - loss: 0.1341 - acc: 0.0842 - val_loss: 0.2144 - val_acc: 0.0711\n",
      "Epoch 64/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1334 - acc: 0.0844 - val_loss: 0.2149 - val_acc: 0.0711\n",
      "Epoch 65/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1324 - acc: 0.0848 - val_loss: 0.2158 - val_acc: 0.0710\n",
      "Epoch 66/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1317 - acc: 0.0850 - val_loss: 0.2164 - val_acc: 0.0711\n",
      "Epoch 67/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1311 - acc: 0.0851 - val_loss: 0.2175 - val_acc: 0.0709\n",
      "Epoch 68/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1301 - acc: 0.0855 - val_loss: 0.2196 - val_acc: 0.0707\n",
      "Epoch 69/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1294 - acc: 0.0857 - val_loss: 0.2219 - val_acc: 0.0700\n",
      "Epoch 70/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1288 - acc: 0.0859 - val_loss: 0.2218 - val_acc: 0.0701\n",
      "Epoch 71/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1280 - acc: 0.0861 - val_loss: 0.2211 - val_acc: 0.0707\n",
      "Epoch 72/100\n",
      "8605/8605 [==============================] - 148s 17ms/step - loss: 0.1273 - acc: 0.0863 - val_loss: 0.2216 - val_acc: 0.0703\n",
      "Epoch 73/100\n",
      "8605/8605 [==============================] - 150s 17ms/step - loss: 0.1265 - acc: 0.0865 - val_loss: 0.2243 - val_acc: 0.0700\n",
      "Epoch 74/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1258 - acc: 0.0867 - val_loss: 0.2249 - val_acc: 0.0698\n",
      "Epoch 75/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1253 - acc: 0.0868 - val_loss: 0.2248 - val_acc: 0.0700\n",
      "Epoch 76/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1247 - acc: 0.0871 - val_loss: 0.2258 - val_acc: 0.0700\n",
      "Epoch 77/100\n",
      "8605/8605 [==============================] - 152s 18ms/step - loss: 0.1240 - acc: 0.0873 - val_loss: 0.2290 - val_acc: 0.0696\n",
      "Epoch 78/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1235 - acc: 0.0875 - val_loss: 0.2288 - val_acc: 0.0699\n",
      "Epoch 79/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1227 - acc: 0.0877 - val_loss: 0.2285 - val_acc: 0.0696\n",
      "Epoch 80/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1222 - acc: 0.0878 - val_loss: 0.2289 - val_acc: 0.0697\n",
      "Epoch 81/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1215 - acc: 0.0881 - val_loss: 0.2300 - val_acc: 0.0697\n",
      "Epoch 82/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1211 - acc: 0.0881 - val_loss: 0.2305 - val_acc: 0.0696\n",
      "Epoch 83/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1205 - acc: 0.0883 - val_loss: 0.2317 - val_acc: 0.0694\n",
      "Epoch 84/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1200 - acc: 0.0885 - val_loss: 0.2342 - val_acc: 0.0694\n",
      "Epoch 85/100\n",
      "8605/8605 [==============================] - 148s 17ms/step - loss: 0.1194 - acc: 0.0886 - val_loss: 0.2378 - val_acc: 0.0690\n",
      "Epoch 86/100\n",
      "8605/8605 [==============================] - 148s 17ms/step - loss: 0.1189 - acc: 0.0888 - val_loss: 0.2341 - val_acc: 0.0693\n",
      "Epoch 87/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1186 - acc: 0.0889 - val_loss: 0.2350 - val_acc: 0.0693\n",
      "Epoch 88/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1179 - acc: 0.0891 - val_loss: 0.2360 - val_acc: 0.0692\n",
      "Epoch 89/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1176 - acc: 0.0892 - val_loss: 0.2363 - val_acc: 0.0692\n",
      "Epoch 90/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1171 - acc: 0.0893 - val_loss: 0.2379 - val_acc: 0.0691\n",
      "Epoch 91/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1166 - acc: 0.0894 - val_loss: 0.2386 - val_acc: 0.0689\n",
      "Epoch 92/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1162 - acc: 0.0896 - val_loss: 0.2393 - val_acc: 0.0691\n",
      "Epoch 93/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1157 - acc: 0.0898 - val_loss: 0.2393 - val_acc: 0.0692\n",
      "Epoch 94/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1155 - acc: 0.0898 - val_loss: 0.2408 - val_acc: 0.0691\n",
      "Epoch 95/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1149 - acc: 0.0900 - val_loss: 0.2415 - val_acc: 0.0687\n",
      "Epoch 96/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1146 - acc: 0.0900 - val_loss: 0.2423 - val_acc: 0.0688\n",
      "Epoch 97/100\n",
      "8605/8605 [==============================] - 148s 17ms/step - loss: 0.1142 - acc: 0.0902 - val_loss: 0.2441 - val_acc: 0.0689\n",
      "Epoch 98/100\n",
      "8605/8605 [==============================] - 149s 17ms/step - loss: 0.1139 - acc: 0.0902 - val_loss: 0.2425 - val_acc: 0.0688\n",
      "Epoch 99/100\n",
      "8605/8605 [==============================] - 148s 17ms/step - loss: 0.1132 - acc: 0.0904 - val_loss: 0.2440 - val_acc: 0.0688\n",
      "Epoch 100/100\n",
      "8605/8605 [==============================] - 147s 17ms/step - loss: 0.1132 - acc: 0.0904 - val_loss: 0.2458 - val_acc: 0.0686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24296a2b0f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "num_neurons = 256\n",
    "\n",
    "encoder_inputs = Input(shape=(None, input_vocab_size))\n",
    "encoder = LSTM(num_neurons, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, output_vocab_size))\n",
    "decoder_lstm = LSTM(num_neurons, return_sequences=True,\n",
    "                    return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.fit([encoder_input_data, decoder_input_data],\n",
    "          decoder_target_data, batch_size=batch_size, epochs=epochs,\n",
    "          validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_structure = model.to_json()\n",
    "with open(\"casablancalstmmodel1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_structure)\n",
    "model.save_weights(\"casablanca_lstm_weights1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbark\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "thought_input = [\n",
    "    Input(shape=(num_neurons,)), Input(shape=(num_neurons,))]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=thought_input)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    inputs=[decoder_inputs] + thought_input,\n",
    "    output=[decoder_outputs] + decoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "\n",
    "def instantiate_seq2seq_model(num_encoder_tokens, num_decoder_tokens, num_neurons=256):\n",
    "\n",
    "    encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = LSTM(num_neurons, return_state=True)\n",
    "    _, state_h, state_c = encoder(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "    decoder_lstm = LSTM(num_neurons, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                         initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_state_input_h = Input(shape=(num_neurons,))\n",
    "    decoder_state_input_c = Input(shape=(num_neurons,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "\n",
    "    return model, encoder_model, decoder_model\n",
    "\n",
    "\n",
    "def construct_seq2seq_model(num_encoder_tokens, num_decoder_tokens, num_neurons=256):\n",
    "\n",
    "    encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = LSTM(num_neurons, return_state=True)\n",
    "    _, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "    decoder_lstm = LSTM(num_neurons, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                         initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_len = df_input.i.str.len().max()\n",
    "# max_encoder_seq_len\n",
    "# 100\n",
    "max_decoder_seq_len = df_output.o.str.len().max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbark\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "thought_input = [\n",
    "    Input(shape=(num_neurons,)), Input(shape=(num_neurons,))]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=thought_input)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    inputs=[decoder_inputs] + thought_input,\n",
    "    output=[decoder_outputs] + decoder_states)\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    thought = encoder_model.predict(input_seq)  # <1>\n",
    "\n",
    "    target_seq = np.zeros((1, 1, len(output_vocabulary)))  # <2>\n",
    "    target_seq[0, 0, output_vocabulary.index(stop_token)\n",
    "        ] = 1.  # <3>\n",
    "    stop_condition = False\n",
    "    generated_sequence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + thought) # <4>\n",
    "\n",
    "        generated_token_idx = np.argmax(output_tokens[0, -1, :])\n",
    "        generated_char = output_vocabulary[generated_token_idx]\n",
    "        generated_sequence += generated_char\n",
    "        if (generated_char == stop_token or\n",
    "                len(generated_sequence) > max_decoder_seq_len\n",
    "                ):  # <5>\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, len(output_vocabulary)))  # <6>\n",
    "        target_seq[0, 0, generated_token_idx] = 1.\n",
    "        thought = [h, c]  # <7>\n",
    "\n",
    "    return generated_sequence\n",
    "\n",
    "def respond(input_text):\n",
    "    input_text = input_text.lower()\n",
    "    input_text = ''.join(c if c in input_vocabulary else ' ' for c in input_text)\n",
    "    input_seq = np.zeros((1, max_encoder_seq_len, len(input_vocabulary)), dtype='float32')\n",
    "    for t, c in enumerate(input_text):\n",
    "        input_seq[0, t, input_vocabulary.index(c)] = 1.\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('Human: {}'.format(input_text))\n",
    "    print('Bot:', decoded_sentence)\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: hi rosa, how are you?\n",
      "Bot: I can't help you that.  What seems looking at the the staming people saying the sholl crazy?\n",
      "\n",
      "Human: hi jim, how are you?\n",
      "Bot: I can't help you that.  What seems looking at the the staming people saying the shele write she did nothing left is herous again.\n",
      "\n",
      "Human: hi barak, how are you?\n",
      "Bot: I can't help you that.  What seems looking at the the staming people saying the sholl crazy?\n",
      "\n",
      "Human: hi amy, how are you?\n",
      "Bot: I can't help you that.  What seems looking at the the staming people saying the sholl crazy?\n",
      "\n",
      "Human: hi paris, how are you?\n",
      "Bot: Well, I can't ready something I want to be happy.\n",
      "\n",
      "Human: hi joe, how are you?\n",
      "Bot: I can't help you that.  What seems looking at the the staming people saying the shele write she did nothing left is herous again.\n",
      "\n",
      "Human: hi jane, how are you?\n",
      "Bot: I can't help you that.  What seems looking at the the staming people saying the shele write she did nothing left is herous again.\n",
      "\n",
      "Human: hey jane, how are you?\n",
      "Bot: I don't know.  I don't think so.\n",
      "\n",
      "Human: hey jon, how are you?\n",
      "Bot: I don't know.  I don't think so.\n",
      "\n",
      "Human: hey john, how are you?\n",
      "Bot: I don't know.  I don't think so.\n",
      "\n",
      "Human: hey joe, how are you?\n",
      "Bot: I don't know.  I don't think so.\n",
      "\n",
      "Human: hey jim, how are you?\n",
      "Bot: I don't know.  I don't think so.\n",
      "\n",
      "Human: hey ashley, how are you?\n",
      "Bot: I don't know.  I don't think so.\n",
      "\n",
      "Human: hey my love, how are you?\n",
      "Bot: I don't know.  I don't think so.\n",
      "\n",
      "Human: hey arzu, how are you?\n",
      "Bot: I don't know.  I don't think so.\n",
      "\n",
      "Human: i'm talking about us.\n",
      "Bot: I can't help you that.  What seems looking at the first place that move is old girl?  It sweat to stay one six enood of eatt...\n",
      "\n",
      "Human: what are you trying to say?\n",
      "Bot: I don't know.  I don't know.  I was so tarking it all the trub back on the street birthday now and I have no idea...  it to kill off. I love you.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know.  I don't know.  I was so tarking it all the trub back on the street birthday now and I have no idea...  it to kill off. I love you.\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond('Hi Rosa, how are you?')\n",
    "respond('Hi Jim, how are you?')\n",
    "respond('Hi Barak, how are you?')\n",
    "respond('Hi Amy, how are you?')\n",
    "respond('Hi Paris, how are you?')\n",
    "respond('Hi Joe, how are you?')\n",
    "respond('Hi Jane, how are you?')\n",
    "respond('Hey Jane, how are you?')\n",
    "respond('Hey Jon, how are you?')\n",
    "respond('Hey John, how are you?')\n",
    "respond('Hey Joe, how are you?')\n",
    "respond('Hey Jim, how are you?')\n",
    "respond('Hey Ashley, how are you?')\n",
    "respond('Hey my love, how are you?')\n",
    "respond('Hey Arzu, how are you?')\n",
    "respond(\"I'm talking about us.\")\n",
    "respond(\"What are you trying to say?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: are you crazy?\n",
      "Bot: I think the say I'm a lot of man and then we have to go to the way they want to go out with anything with you.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I think the say I'm a lot of man and then we have to go to the way they want to go out with anything with you.\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond('Are you crazy?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: what is perry como up to?\n",
      "Bot: Yes.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes.\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond('What is perry Como up to?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: it is a beautiful day today.\n",
      "Bot: I don't know.  I mean the man and I know what I think.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know.  I mean the man and I know what I think.\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond('It is a beautiful day today.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: hey arzu, how are you?\n",
      "Bot: Y she's bean a break doy to the wedding and I'm not going to have sex what I was ling.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Y she's bean a break doy to the wedding and I'm not going to have sex what I was ling.\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond('Hey Arzu, how are you?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
